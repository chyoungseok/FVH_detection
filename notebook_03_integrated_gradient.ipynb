{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3819e249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, torch, numpy as np\n",
    "from modules.ig_utils import ig_analysis\n",
    "from modules.model_utils import model_loss_optimizer_resnet\n",
    "\n",
    "device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model, _, _ = model_loss_optimizer_resnet(\n",
    "    device=device, weight_pos=1.0, lr=1e-3, show_model_summary=False, resnet_depth=50\n",
    ")\n",
    "ckpt_path = \"/zdisk/users/ext_user_03/01_yschoi/project_01_FVH_detection/02_results/fhv_resnet50_with_cam/best_model.pt\"  # ← 너의 체크포인트\n",
    "ckpt = torch.load(\n",
    "    ckpt_path,\n",
    "    map_location=device if isinstance(device, str) else None,\n",
    "    weights_only=False \n",
    "    ) if os.path.exists(ckpt_path) else None\n",
    "\n",
    "if ckpt and 'model' in ckpt:\n",
    "    model.load_state_dict(ckpt['model'])\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bfcb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_test_data = '/zdisk/users/ext_user_03/01_yschoi/project_01_FVH_detection/02_results/fhv_resnet50_with_cam/test_data.npy'\n",
    "test_data = np.load(path_test_data)\n",
    "\n",
    "path_test_label = '/zdisk/users/ext_user_03/01_yschoi/project_01_FVH_detection/02_results/fhv_resnet50_with_cam/test_y_true.npy'\n",
    "test_label = np.load(path_test_label)\n",
    "\n",
    "from modules.data_utils import SliceDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "batch_size = 1\n",
    "num_workers = 0\n",
    "ds_test  = SliceDataset(test_data, test_label)\n",
    "dl_test  = DataLoader(ds_test,  batch_size=batch_size, shuffle=False,\n",
    "                      num_workers=num_workers, pin_memory=False,\n",
    "                      persistent_workers=False if num_workers == 0 else True)\n",
    "\n",
    "from modules.ig_utils import ig_on_batch\n",
    "\n",
    "model.eval()  # 반드시 eval\n",
    "\n",
    "idx = 0\n",
    "for images, labels in dl_test:           # images: (B,1,672,672)\n",
    "    # 배치 한 번에 IG 계산 + PNG 저장\n",
    "    res_list = ig_on_batch(\n",
    "        model=model,\n",
    "        batch_images=images,            # (B,1,H,W) 그대로 전달\n",
    "        device=\"cuda:1\",\n",
    "        out_dir=\"./02_results/fhv_resnet50_with_cam/ig_test\", # PNG는 runs/ig_batch_demo/ig_batch/*.png 로 저장\n",
    "        fname_index=idx,\n",
    "        ig_steps=64,\n",
    "        ig_target=\"pos\",                # 1-logit이면 sign(+), multi-logit이면 pos_class_idx 사용\n",
    "        pos_class_idx=1,                # multi-logit에서 양성 클래스 인덱스가 1이라면\n",
    "        baseline_mode=\"zeros\",          # 'zeros'|'constant'|'blur'\n",
    "        use_noise_tunnel=False,         # 필요시 True로\n",
    "        viz_sign=\"positive\",            # 'positive'|'negative'|'both'|'absolute'\n",
    "        display_mode=\"percentile\",      # 'percentile'|'zscore'\n",
    "        save_raw_attr=False\n",
    "    )\n",
    "    idx += 1\n",
    "\n",
    "    # 선택: res_list[i]에는 각 샘플의 attr/overlay/score/delta 등이 들어있음\n",
    "    # 여기서는 이미지 파일 저장만 쓰는 경우 res_list를 굳이 보관할 필요 없음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12be879b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = test_data[1]\n",
    "test_y = test_label[1]\n",
    "\n",
    "# 1채널 → 3채널 복제\n",
    "sl_3ch = np.repeat(test_x[None, ...], 3, axis=0)  # (3,H,W)\n",
    "x = torch.from_numpy(sl_3ch)[None, ...]       # (1,3,H,W)\n",
    "x = x.to(device)\n",
    "\n",
    "# 아주 간단한 DataLoader 구성 (배치 1개)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "ds = TensorDataset(x)  # 라벨은 없어도 됨\n",
    "dl_test = DataLoader(ds, batch_size=1, shuffle=False)\n",
    "len(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1385f77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first conv in_channels = 1\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# 1) 첫 Conv가 1채널인 모델을 위한 래퍼 (3→1 평균)\n",
    "class Force1Channel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        # x: (B,C,H,W)\n",
    "        if x.shape[1] == 3:\n",
    "            x = x.mean(dim=1, keepdim=True)  # 3→1\n",
    "        return self.model(x)\n",
    "\n",
    "# 2) 첫 Conv가 3채널인 모델을 위한 래퍼 (1→3 복제)\n",
    "class Force3Channel(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        if x.shape[1] == 1:\n",
    "            x = x.repeat(1, 3, 1, 1)  # 1→3\n",
    "        return self.model(x)\n",
    "\n",
    "# 3) 네 모델 구조 확인\n",
    "import torch.nn as nn\n",
    "first_in = next(m.in_channels for m in model.modules() if isinstance(m, nn.Conv2d))\n",
    "print(\"first conv in_channels =\", first_in)\n",
    "\n",
    "# 4) in_channels=1 이라면:\n",
    "if first_in == 1:\n",
    "    wrapped = Force1Channel(model).to(device).eval()\n",
    "else:\n",
    "    wrapped = Force3Channel(model).to(device).eval()\n",
    "\n",
    "# 5) IG 실행 (denorm은 1채널 모델이면 None 권장)\n",
    "ig_analysis(\n",
    "    out_dir='./tmp_ig_demo/',\n",
    "    model=wrapped,          # ← 래퍼로 감싼 모델을 전달\n",
    "    dl_test=dl_test,\n",
    "    device=device,\n",
    "    export_ig=True,\n",
    "    ig_steps=128,\n",
    "    ig_alpha=0.5,\n",
    "    ig_cmap=\"jet\",\n",
    "    ig_target=\"pos\",\n",
    "    ig_positive_only=True,\n",
    "    mean_for_denorm=None,   # 1채널이면 None\n",
    "    std_for_denorm=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adbbdee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./tmp_ig_demo/ig_test/ig_000000.png']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from modules.ig_utils import ig_analysis\n",
    "saved = ig_analysis(\n",
    "    out_dir=\"./tmp_ig_demo\",\n",
    "    model=model,            # 학습된 모델 (ckpt 로드 후 .eval())\n",
    "    dl_test=dl_test,        # 너의 테스트 DataLoader\n",
    "    device=\"cuda\",\n",
    "    export_ig=True,\n",
    "    ig_steps=128,\n",
    "    ig_alpha=0.5,\n",
    "    ig_cmap=\"jet\",\n",
    "    ig_target=\"pos\",        # 2-logit: class 1 / 1-logit: sign(+)\n",
    "    ig_positive_only=True,\n",
    "    mean_for_denorm=None,   # 1채널 모델이면 None 권장 (자동 정렬됨)\n",
    "    std_for_denorm=None,\n",
    "    save_raw_attr=False,\n",
    ")\n",
    "saved[:3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fhv_deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
