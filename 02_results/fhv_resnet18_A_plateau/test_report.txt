=== Validation (best) Metrics ===
ACC: 0.7831
PREC: 0.7156
REC: 0.9398
F1: 0.8125
AUC: 0.8241
CM:
[[52 31]
 [ 5 78]]

=== Test Metrics ===
ACC: 0.7989
PREC: 0.7346
REC: 0.9358
F1: 0.8231
AUC: 0.8638
CM:
[[237 121]
 [ 23 335]]

=== Classification Report (thr=0.5) ===
              precision    recall  f1-score   support

           0     0.9115    0.6620    0.7670       358
           1     0.7346    0.9358    0.8231       358

    accuracy                         0.7989       716
   macro avg     0.8231    0.7989    0.7950       716
weighted avg     0.8231    0.7989    0.7950       716
