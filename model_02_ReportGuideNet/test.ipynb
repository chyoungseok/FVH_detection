{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d328015c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42435 9030 9048\n",
      "Train pos_weight: tensor(48.4580)\n",
      "torch.Size([8, 1, 672, 672]) torch.Size([8])\n",
      "['BP00518_P16950', 'HP00094_P01876', 'HP00055_P05753', 'HP00421_P07283', 'HP00722_P07404', 'HP00334_P04870', 'HP00141_P01647', 'HP00770_P05887']\n",
      "tensor([ 7, 20,  5, 16, 21, 20,  1, 19])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "from PlainNet import FlairNPYSliceDataset, compute_pos_weight_from_dataset\n",
    "\n",
    "path_data = \"../01_data/04_flair_preproc_slices/\"\n",
    "train_ds = FlairNPYSliceDataset(root_dir=path_data, split=\"train\")\n",
    "val_ds   = FlairNPYSliceDataset(root_dir=path_data, split=\"val\")\n",
    "test_ds  = FlairNPYSliceDataset(root_dir=path_data, split=\"test\")\n",
    "\n",
    "print(len(train_ds), len(val_ds), len(test_ds))\n",
    "\n",
    "# pos_weight 계산\n",
    "print(\"Train pos_weight:\", compute_pos_weight_from_dataset(train_ds))\n",
    "\n",
    "# dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=0)\n",
    "batch = next(iter(train_loader))\n",
    "print(batch[\"image\"].shape, batch[\"label\"].shape)\n",
    "print(batch[\"subject_id\"])         # e.g. ['subject1', 'subject3', ...]\n",
    "print(batch[\"slice_idx\"])          # e.g. [12, 45, 3, 88, ...]\n",
    "print(batch[\"label\"])\n",
    "# torch.Size([8,1,672,672]) torch.Size([8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8f38e389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 672, 672]) torch.Size([8])\n",
      "['HP00209_P02691', 'HP00729_P04570', 'HP00130_P04420', 'BP00185_P13256', 'BP00376_P11730', 'BP00418_P12627', 'BP00139_P12079', 'HP00878_P07632']\n",
      "tensor([12, 13,  9,  7, 22, 22,  2,  4])\n",
      "tensor([0., 1., 0., 0., 0., 0., 0., 0.])\n",
      "['HP00729_P04570']\n",
      "tensor([13])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "batch = next(iter(train_loader))\n",
    "print(batch[\"image\"].shape, batch[\"label\"].shape)\n",
    "print(batch[\"subject_id\"])         # e.g. ['subject1', 'subject3', ...]\n",
    "print(batch[\"slice_idx\"])          # e.g. [12, 45, 3, 88, ...]\n",
    "print(batch[\"label\"])\n",
    "\n",
    "idx = np.arange(8)[batch[\"label\"] == 1]\n",
    "print(np.array(batch[\"subject_id\"])[idx])\n",
    "print(batch['slice_idx'][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43936846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 336, 336]           3,136\n",
      "       BatchNorm2d-2         [-1, 64, 336, 336]             128\n",
      "              ReLU-3         [-1, 64, 336, 336]               0\n",
      "         MaxPool2d-4         [-1, 64, 168, 168]               0\n",
      "            Conv2d-5         [-1, 64, 168, 168]          36,864\n",
      "       BatchNorm2d-6         [-1, 64, 168, 168]             128\n",
      "              ReLU-7         [-1, 64, 168, 168]               0\n",
      "            Conv2d-8         [-1, 64, 168, 168]          36,864\n",
      "       BatchNorm2d-9         [-1, 64, 168, 168]             128\n",
      "             ReLU-10         [-1, 64, 168, 168]               0\n",
      "       BasicBlock-11         [-1, 64, 168, 168]               0\n",
      "           Conv2d-12         [-1, 64, 168, 168]          36,864\n",
      "      BatchNorm2d-13         [-1, 64, 168, 168]             128\n",
      "             ReLU-14         [-1, 64, 168, 168]               0\n",
      "           Conv2d-15         [-1, 64, 168, 168]          36,864\n",
      "      BatchNorm2d-16         [-1, 64, 168, 168]             128\n",
      "             ReLU-17         [-1, 64, 168, 168]               0\n",
      "       BasicBlock-18         [-1, 64, 168, 168]               0\n",
      "           Conv2d-19          [-1, 128, 84, 84]          73,728\n",
      "      BatchNorm2d-20          [-1, 128, 84, 84]             256\n",
      "             ReLU-21          [-1, 128, 84, 84]               0\n",
      "           Conv2d-22          [-1, 128, 84, 84]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 84, 84]             256\n",
      "           Conv2d-24          [-1, 128, 84, 84]           8,192\n",
      "      BatchNorm2d-25          [-1, 128, 84, 84]             256\n",
      "             ReLU-26          [-1, 128, 84, 84]               0\n",
      "       BasicBlock-27          [-1, 128, 84, 84]               0\n",
      "           Conv2d-28          [-1, 128, 84, 84]         147,456\n",
      "      BatchNorm2d-29          [-1, 128, 84, 84]             256\n",
      "             ReLU-30          [-1, 128, 84, 84]               0\n",
      "           Conv2d-31          [-1, 128, 84, 84]         147,456\n",
      "      BatchNorm2d-32          [-1, 128, 84, 84]             256\n",
      "             ReLU-33          [-1, 128, 84, 84]               0\n",
      "       BasicBlock-34          [-1, 128, 84, 84]               0\n",
      "           Conv2d-35          [-1, 256, 42, 42]         294,912\n",
      "      BatchNorm2d-36          [-1, 256, 42, 42]             512\n",
      "             ReLU-37          [-1, 256, 42, 42]               0\n",
      "           Conv2d-38          [-1, 256, 42, 42]         589,824\n",
      "      BatchNorm2d-39          [-1, 256, 42, 42]             512\n",
      "           Conv2d-40          [-1, 256, 42, 42]          32,768\n",
      "      BatchNorm2d-41          [-1, 256, 42, 42]             512\n",
      "             ReLU-42          [-1, 256, 42, 42]               0\n",
      "       BasicBlock-43          [-1, 256, 42, 42]               0\n",
      "           Conv2d-44          [-1, 256, 42, 42]         589,824\n",
      "      BatchNorm2d-45          [-1, 256, 42, 42]             512\n",
      "             ReLU-46          [-1, 256, 42, 42]               0\n",
      "           Conv2d-47          [-1, 256, 42, 42]         589,824\n",
      "      BatchNorm2d-48          [-1, 256, 42, 42]             512\n",
      "             ReLU-49          [-1, 256, 42, 42]               0\n",
      "       BasicBlock-50          [-1, 256, 42, 42]               0\n",
      "           Conv2d-51          [-1, 512, 21, 21]       1,179,648\n",
      "      BatchNorm2d-52          [-1, 512, 21, 21]           1,024\n",
      "             ReLU-53          [-1, 512, 21, 21]               0\n",
      "           Conv2d-54          [-1, 512, 21, 21]       2,359,296\n",
      "      BatchNorm2d-55          [-1, 512, 21, 21]           1,024\n",
      "           Conv2d-56          [-1, 512, 21, 21]         131,072\n",
      "      BatchNorm2d-57          [-1, 512, 21, 21]           1,024\n",
      "             ReLU-58          [-1, 512, 21, 21]               0\n",
      "       BasicBlock-59          [-1, 512, 21, 21]               0\n",
      "           Conv2d-60          [-1, 512, 21, 21]       2,359,296\n",
      "      BatchNorm2d-61          [-1, 512, 21, 21]           1,024\n",
      "             ReLU-62          [-1, 512, 21, 21]               0\n",
      "           Conv2d-63          [-1, 512, 21, 21]       2,359,296\n",
      "      BatchNorm2d-64          [-1, 512, 21, 21]           1,024\n",
      "             ReLU-65          [-1, 512, 21, 21]               0\n",
      "       BasicBlock-66          [-1, 512, 21, 21]               0\n",
      "AdaptiveAvgPool2d-67            [-1, 512, 1, 1]               0\n",
      "         Identity-68                  [-1, 512]               0\n",
      "           ResNet-69                  [-1, 512]               0\n",
      "           Linear-70                    [-1, 1]             513\n",
      "================================================================\n",
      "Total params: 11,170,753\n",
      "Trainable params: 11,170,753\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 1.72\n",
      "Forward/backward pass size (MB): 565.04\n",
      "Params size (MB): 42.61\n",
      "Estimated Total Size (MB): 609.38\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "from PlainNet.models.plainnet import PlainNet\n",
    "\n",
    "# 모델 생성\n",
    "model = PlainNet(backbone=\"resnet18\", in_channels=1, pretrained=False)\n",
    "\n",
    "# GPU에 올리기 (CUDA 있으면)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# summary 출력\n",
    "summary(model, input_size=(1, 672, 672))  # (채널, H, W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c9053",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda253eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reportnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
